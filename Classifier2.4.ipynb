{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMCcIhT0tHt0pSxBzcnaPI"},"kernelspec":{"name":"python3","display_name":"Python 3.7.10 64-bit ('pytorch': conda)"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","interpreter":{"hash":"ffee50c534bd7c93a6da5efa13ffce09c64405852368de92133f2be2a09bbb62"}},"cells":[{"cell_type":"code","execution_count":26,"source":["# from google.colab import drive\r\n","# drive.mount('/content/drive')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4zq3T7JSj0P","executionInfo":{"status":"ok","timestamp":1670806472159,"user_tz":300,"elapsed":1968,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"c64de67c-8e68-4aff-e4e0-d52789f3dac8"}},{"cell_type":"code","execution_count":27,"source":["# cd drive/MyDrive/HW/661Project/"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nm9JnRFqStBD","executionInfo":{"status":"ok","timestamp":1670806472160,"user_tz":300,"elapsed":24,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"7fcf1a43-4b5a-4d3a-88ae-8e437ec6cbeb"}},{"cell_type":"code","execution_count":28,"source":["import torch\r\n","import torch.nn as nn\r\n","import torchvision\r\n","import torch.optim as optim\r\n","import torch.nn.functional as F\r\n","from torch.utils.data import DataLoader\r\n","import torchvision.transforms as transforms\r\n","import time"],"outputs":[],"metadata":{"id":"GieF4pM9StFK","executionInfo":{"status":"ok","timestamp":1670806472160,"user_tz":300,"elapsed":19,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}}}},{"cell_type":"code","execution_count":29,"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","        super(Net, self).__init__()\r\n","        self.conv1 = nn.Conv2d(3, 8, 5)\r\n","        self.conv2 = nn.Conv2d(8, 16, 3)\r\n","        self.conv3 = nn.Conv2d(16, 32, 3)\r\n","        self.bn1 = nn.BatchNorm2d(8)\r\n","        self.bn2 = nn.BatchNorm2d(16)\r\n","        self.bn3 = nn.BatchNorm2d(32)\r\n","        self.fc1 = nn.Linear(32*6*6, 120)\r\n","        self.fc2 = nn.Linear(120, 84)\r\n","        self.fc3 = nn.Linear(84, 10)\r\n","        self.fc4 = nn.Linear(10, 2)\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = F.max_pool2d(out, 2)\r\n","        out = F.relu(self.bn2(self.conv2(out)))\r\n","        out = F.max_pool2d(out, 2)\r\n","        out = F.relu(self.bn3(self.conv3(out)))\r\n","        out = F.max_pool2d(out, 2)\r\n","        out = out.view(out.size(0), -1)\r\n","        out = F.relu(self.fc1(out))\r\n","        out = F.relu(self.fc2(out))\r\n","        out = F.relu(self.fc3(out))\r\n","        # out = self.fc3(out)\r\n","        out = self.fc4(out)\r\n","        return out"],"outputs":[],"metadata":{"id":"Bd9F6V30h_ov","executionInfo":{"status":"ok","timestamp":1670806472161,"user_tz":300,"elapsed":19,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}}}},{"cell_type":"code","execution_count":30,"source":["##Do Not Touch This Cell\r\n","\r\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n","net = Net().to(device)\r\n","# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\r\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\r\n","if device =='cuda':\r\n","    print(\"Train on GPU...\")\r\n","else:\r\n","    print(\"Train on CPU...\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train on GPU...\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oySgLPEviPSP","executionInfo":{"status":"ok","timestamp":1670806472161,"user_tz":300,"elapsed":18,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"466a79f0-daf9-4b38-c661-a926b5d291a7"}},{"cell_type":"code","execution_count":31,"source":["##Do Not Touch This Cell\r\n","max_epochs = 300\r\n","\r\n","random_seed = 671\r\n","torch.manual_seed(random_seed)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x2b337f875b0>"]},"metadata":{},"execution_count":31}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kQbAEVficuZ","executionInfo":{"status":"ok","timestamp":1670806472162,"user_tz":300,"elapsed":13,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"de8a303f-f874-4d0d-bb19-e36623e9cde4"}},{"cell_type":"code","execution_count":32,"source":["crop_size = 64\r\n","\r\n","data_transforms ={\r\n","    'train': transforms.Compose([\r\n","        transforms.RandomResizedCrop(size=crop_size, scale=(0.5, 1.0)),\r\n","        # transforms.RandomHorizontalFlip(),\r\n","        transforms.ToTensor(),\r\n","        transforms.Normalize([.5, .5, .5],[.5, .5, .5])\r\n","    ]),\r\n","    'test': transforms.Compose([\r\n","        transforms.RandomResizedCrop(size=crop_size, scale=(0.5, 1.0)),\r\n","        # transforms.Resize(256),\r\n","        # transforms.CenterCrop(224),\r\n","        transforms.ToTensor(),\r\n","        transforms.Normalize([.5, .5, .5],[.5, .5, .5])\r\n","    ])\r\n","}\r\n","\r\n","train_set = torchvision.datasets.ImageFolder(root='./training set reenact/', transform=data_transforms['train'])\r\n","train_loader = DataLoader(dataset=train_set, batch_size=128, shuffle=True, num_workers=0)\r\n","\r\n","test_set = torchvision.datasets.ImageFolder(root='./testing set reenact/', transform=data_transforms['test'])\r\n","test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=True, num_workers=0)"],"outputs":[],"metadata":{"id":"Bea82HDJTllT","executionInfo":{"status":"ok","timestamp":1670806472163,"user_tz":300,"elapsed":11,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}}}},{"cell_type":"code","execution_count":33,"source":["loss_list, acc_list = [], []\r\n","loss_list_val, acc_list_val = [], []\r\n","criterion = nn.CrossEntropyLoss()\r\n","\r\n","start = time.time()\r\n","\r\n","for epoch in range(max_epochs):\r\n","    #TODO: set the net to train mode:\r\n","    net.train()\r\n","\r\n","    epoch_loss = 0.0\r\n","    correct = 0\r\n","    total_examples = 0\r\n","    for batch_idx, (data, labels) in enumerate(train_loader):\r\n","        data, labels = data.to(device), labels.to(device)\r\n","\r\n","        optimizer.zero_grad()\r\n","        ##TODO: pass the data into the network and store the output\r\n","        outputs = net(data)\r\n","        ##TODO: Calculate the cross entropy loss between the output and target \r\n","        loss = criterion(outputs, labels)\r\n","        ##TODO: Perform backpropagation\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","\r\n","        ##TODO: Get the prediction from the output\r\n","        _, predicted = torch.max(outputs, 1)\r\n","\r\n","\r\n","        # print(f'outputs:{outputs}')\r\n","        # print(f'predicted:{predicted}')\r\n","        # print(f'labels:{labels}')\r\n","\r\n","\r\n","        ##TODO: Calculate the correct number and add the number to correct\r\n","        correct += predicted.eq(labels).sum()\r\n","        total_examples += labels.size(0)\r\n","        ##TODO: Add the loss to epoch_loss.\r\n","        epoch_loss += loss.item()\r\n","    ##TODO: calculate the average loss\r\n","    avg_loss = epoch_loss / len(train_loader)\r\n","    ##TODO: calculate the average accuracy\r\n","    avg_acc = correct / total_examples\r\n","    ##TODO: append average epoch loss to loss list\r\n","    loss_list.append(avg_loss)\r\n","    ##TODO: append average accuracy to accuracy list\r\n","    acc_list.append(avg_acc)\r\n","        \r\n","    print('[epoch %d] loss: %.5f accuracy: %.4f time: %.4fs' % (epoch + 1, avg_loss, avg_acc, time.time()-start))"],"outputs":[{"output_type":"stream","name":"stdout","text":["[epoch 1] loss: 0.69511 accuracy: 0.5041 time: 0.2645s\n","[epoch 2] loss: 0.69529 accuracy: 0.5041 time: 0.5535s\n","[epoch 3] loss: 0.69463 accuracy: 0.5124 time: 0.8565s\n","[epoch 4] loss: 0.69472 accuracy: 0.5041 time: 1.1560s\n","[epoch 5] loss: 0.69357 accuracy: 0.5124 time: 1.4350s\n","[epoch 6] loss: 0.69206 accuracy: 0.4959 time: 1.7390s\n","[epoch 7] loss: 0.69513 accuracy: 0.4959 time: 1.9945s\n","[epoch 8] loss: 0.69382 accuracy: 0.4959 time: 2.2556s\n","[epoch 9] loss: 0.69436 accuracy: 0.5124 time: 2.5077s\n","[epoch 10] loss: 0.69341 accuracy: 0.5124 time: 2.7884s\n","[epoch 11] loss: 0.69291 accuracy: 0.5041 time: 3.0560s\n","[epoch 12] loss: 0.69216 accuracy: 0.4876 time: 3.3226s\n","[epoch 13] loss: 0.69311 accuracy: 0.5041 time: 3.7236s\n","[epoch 14] loss: 0.69025 accuracy: 0.5041 time: 3.9706s\n","[epoch 15] loss: 0.68979 accuracy: 0.5124 time: 4.2224s\n","[epoch 16] loss: 0.69049 accuracy: 0.5124 time: 4.4733s\n","[epoch 17] loss: 0.69047 accuracy: 0.5207 time: 4.7524s\n","[epoch 18] loss: 0.68898 accuracy: 0.4793 time: 5.0089s\n","[epoch 19] loss: 0.68914 accuracy: 0.5289 time: 5.2750s\n","[epoch 20] loss: 0.68858 accuracy: 0.5207 time: 5.5505s\n","[epoch 21] loss: 0.68882 accuracy: 0.5207 time: 5.9565s\n","[epoch 22] loss: 0.68718 accuracy: 0.5372 time: 6.2341s\n","[epoch 23] loss: 0.68861 accuracy: 0.5041 time: 6.5082s\n","[epoch 24] loss: 0.68884 accuracy: 0.5702 time: 6.7569s\n","[epoch 25] loss: 0.68793 accuracy: 0.5289 time: 7.0260s\n","[epoch 26] loss: 0.68606 accuracy: 0.5537 time: 7.3047s\n","[epoch 27] loss: 0.68609 accuracy: 0.5124 time: 7.6237s\n","[epoch 28] loss: 0.68839 accuracy: 0.5124 time: 7.9557s\n","[epoch 29] loss: 0.68508 accuracy: 0.5455 time: 8.2843s\n","[epoch 30] loss: 0.68601 accuracy: 0.5455 time: 8.5920s\n","[epoch 31] loss: 0.68534 accuracy: 0.5702 time: 8.8910s\n","[epoch 32] loss: 0.68596 accuracy: 0.5702 time: 9.1400s\n","[epoch 33] loss: 0.68415 accuracy: 0.5950 time: 9.3906s\n","[epoch 34] loss: 0.68637 accuracy: 0.5455 time: 9.6411s\n","[epoch 35] loss: 0.68177 accuracy: 0.6033 time: 9.8897s\n","[epoch 36] loss: 0.68356 accuracy: 0.6116 time: 10.1745s\n","[epoch 37] loss: 0.68130 accuracy: 0.6529 time: 10.4396s\n","[epoch 38] loss: 0.68339 accuracy: 0.5868 time: 10.7236s\n","[epoch 39] loss: 0.68036 accuracy: 0.6364 time: 11.2336s\n","[epoch 40] loss: 0.68253 accuracy: 0.6694 time: 11.7485s\n","[epoch 41] loss: 0.68037 accuracy: 0.6281 time: 12.2177s\n","[epoch 42] loss: 0.68208 accuracy: 0.6198 time: 12.4907s\n","[epoch 43] loss: 0.67946 accuracy: 0.6116 time: 12.7727s\n","[epoch 44] loss: 0.68080 accuracy: 0.6364 time: 13.0423s\n","[epoch 45] loss: 0.67834 accuracy: 0.6364 time: 13.3224s\n","[epoch 46] loss: 0.67922 accuracy: 0.6281 time: 13.6084s\n","[epoch 47] loss: 0.67562 accuracy: 0.6529 time: 13.9201s\n","[epoch 48] loss: 0.67761 accuracy: 0.6446 time: 14.2081s\n","[epoch 49] loss: 0.67742 accuracy: 0.6281 time: 14.4967s\n","[epoch 50] loss: 0.67550 accuracy: 0.6281 time: 14.8023s\n","[epoch 51] loss: 0.67418 accuracy: 0.6529 time: 15.1927s\n","[epoch 52] loss: 0.67605 accuracy: 0.6942 time: 15.4567s\n","[epoch 53] loss: 0.67603 accuracy: 0.6694 time: 15.7237s\n","[epoch 54] loss: 0.67496 accuracy: 0.6777 time: 15.9896s\n","[epoch 55] loss: 0.67338 accuracy: 0.6612 time: 16.4157s\n","[epoch 56] loss: 0.67086 accuracy: 0.6860 time: 16.6910s\n","[epoch 57] loss: 0.67076 accuracy: 0.6446 time: 16.9756s\n","[epoch 58] loss: 0.67060 accuracy: 0.6612 time: 17.2617s\n","[epoch 59] loss: 0.67221 accuracy: 0.6777 time: 17.5217s\n","[epoch 60] loss: 0.66884 accuracy: 0.6860 time: 17.7907s\n","[epoch 61] loss: 0.66925 accuracy: 0.6942 time: 18.0567s\n","[epoch 62] loss: 0.67012 accuracy: 0.6860 time: 18.6140s\n","[epoch 63] loss: 0.66625 accuracy: 0.7107 time: 18.8882s\n","[epoch 64] loss: 0.66584 accuracy: 0.6529 time: 19.3268s\n","[epoch 65] loss: 0.66825 accuracy: 0.6942 time: 19.6075s\n","[epoch 66] loss: 0.66193 accuracy: 0.7355 time: 19.8766s\n","[epoch 67] loss: 0.66267 accuracy: 0.6694 time: 20.1475s\n","[epoch 68] loss: 0.66389 accuracy: 0.6694 time: 20.4256s\n","[epoch 69] loss: 0.66130 accuracy: 0.6777 time: 20.7071s\n","[epoch 70] loss: 0.65590 accuracy: 0.6860 time: 20.9736s\n","[epoch 71] loss: 0.65898 accuracy: 0.7190 time: 21.2426s\n","[epoch 72] loss: 0.65643 accuracy: 0.7025 time: 21.7703s\n","[epoch 73] loss: 0.65772 accuracy: 0.6777 time: 22.0373s\n","[epoch 74] loss: 0.65285 accuracy: 0.7438 time: 22.3664s\n","[epoch 75] loss: 0.65656 accuracy: 0.6694 time: 22.9431s\n","[epoch 76] loss: 0.65195 accuracy: 0.6942 time: 23.2868s\n","[epoch 77] loss: 0.65179 accuracy: 0.6942 time: 23.5973s\n","[epoch 78] loss: 0.65155 accuracy: 0.7273 time: 24.0219s\n","[epoch 79] loss: 0.64507 accuracy: 0.7355 time: 24.3764s\n","[epoch 80] loss: 0.64706 accuracy: 0.7025 time: 24.6729s\n","[epoch 81] loss: 0.64754 accuracy: 0.7190 time: 24.9385s\n","[epoch 82] loss: 0.64124 accuracy: 0.7273 time: 25.2035s\n","[epoch 83] loss: 0.63544 accuracy: 0.7107 time: 25.4745s\n","[epoch 84] loss: 0.63444 accuracy: 0.7273 time: 25.8196s\n","[epoch 85] loss: 0.64299 accuracy: 0.7107 time: 26.1346s\n","[epoch 86] loss: 0.63063 accuracy: 0.7438 time: 26.4237s\n","[epoch 87] loss: 0.63577 accuracy: 0.6942 time: 26.8758s\n","[epoch 88] loss: 0.63201 accuracy: 0.7521 time: 27.3512s\n","[epoch 89] loss: 0.62741 accuracy: 0.7273 time: 27.6703s\n","[epoch 90] loss: 0.62607 accuracy: 0.7273 time: 27.9760s\n","[epoch 91] loss: 0.63089 accuracy: 0.7190 time: 28.2815s\n","[epoch 92] loss: 0.61810 accuracy: 0.7603 time: 28.5531s\n","[epoch 93] loss: 0.61700 accuracy: 0.7686 time: 28.8389s\n","[epoch 94] loss: 0.62001 accuracy: 0.7355 time: 29.1226s\n","[epoch 95] loss: 0.62340 accuracy: 0.7603 time: 29.6827s\n","[epoch 96] loss: 0.61329 accuracy: 0.7603 time: 30.2613s\n","[epoch 97] loss: 0.61042 accuracy: 0.7603 time: 30.7417s\n","[epoch 98] loss: 0.60793 accuracy: 0.7851 time: 31.2059s\n","[epoch 99] loss: 0.60220 accuracy: 0.7603 time: 31.5069s\n","[epoch 100] loss: 0.60911 accuracy: 0.7769 time: 31.7901s\n","[epoch 101] loss: 0.61137 accuracy: 0.7355 time: 32.0909s\n","[epoch 102] loss: 0.62221 accuracy: 0.6694 time: 32.4054s\n","[epoch 103] loss: 0.59082 accuracy: 0.7686 time: 32.8198s\n","[epoch 104] loss: 0.60381 accuracy: 0.7273 time: 33.1223s\n","[epoch 105] loss: 0.58877 accuracy: 0.7603 time: 33.4213s\n","[epoch 106] loss: 0.58627 accuracy: 0.7851 time: 33.7869s\n","[epoch 107] loss: 0.59546 accuracy: 0.7521 time: 34.1060s\n","[epoch 108] loss: 0.58031 accuracy: 0.7769 time: 34.3895s\n","[epoch 109] loss: 0.57704 accuracy: 0.7686 time: 34.6685s\n","[epoch 110] loss: 0.58254 accuracy: 0.7603 time: 34.9385s\n","[epoch 111] loss: 0.57496 accuracy: 0.7603 time: 35.2096s\n","[epoch 112] loss: 0.57456 accuracy: 0.7934 time: 35.4686s\n","[epoch 113] loss: 0.57372 accuracy: 0.7521 time: 35.9471s\n","[epoch 114] loss: 0.56364 accuracy: 0.7603 time: 36.2182s\n","[epoch 115] loss: 0.55451 accuracy: 0.7851 time: 36.4892s\n","[epoch 116] loss: 0.54534 accuracy: 0.8017 time: 36.7717s\n","[epoch 117] loss: 0.54320 accuracy: 0.7934 time: 37.0357s\n","[epoch 118] loss: 0.53447 accuracy: 0.8430 time: 37.3557s\n","[epoch 119] loss: 0.54277 accuracy: 0.7686 time: 37.6207s\n","[epoch 120] loss: 0.55234 accuracy: 0.7521 time: 37.8827s\n","[epoch 121] loss: 0.52873 accuracy: 0.7769 time: 38.1397s\n","[epoch 122] loss: 0.52792 accuracy: 0.8017 time: 38.4217s\n","[epoch 123] loss: 0.52672 accuracy: 0.8017 time: 38.6937s\n","[epoch 124] loss: 0.52354 accuracy: 0.7769 time: 38.9567s\n","[epoch 125] loss: 0.52672 accuracy: 0.8017 time: 39.2247s\n","[epoch 126] loss: 0.51297 accuracy: 0.7686 time: 39.5078s\n","[epoch 127] loss: 0.52284 accuracy: 0.7686 time: 39.7866s\n","[epoch 128] loss: 0.50268 accuracy: 0.8264 time: 40.1728s\n","[epoch 129] loss: 0.50138 accuracy: 0.7934 time: 40.4684s\n","[epoch 130] loss: 0.48186 accuracy: 0.8099 time: 40.7264s\n","[epoch 131] loss: 0.50229 accuracy: 0.7769 time: 40.9874s\n","[epoch 132] loss: 0.49597 accuracy: 0.8430 time: 41.3050s\n","[epoch 133] loss: 0.50777 accuracy: 0.7851 time: 41.5860s\n","[epoch 134] loss: 0.48559 accuracy: 0.7851 time: 41.8485s\n","[epoch 135] loss: 0.47134 accuracy: 0.8347 time: 42.1175s\n","[epoch 136] loss: 0.47736 accuracy: 0.8264 time: 42.3901s\n","[epoch 137] loss: 0.45619 accuracy: 0.8347 time: 43.1847s\n","[epoch 138] loss: 0.49192 accuracy: 0.7521 time: 43.4412s\n","[epoch 139] loss: 0.47092 accuracy: 0.8182 time: 43.7377s\n","[epoch 140] loss: 0.47706 accuracy: 0.8099 time: 44.0238s\n","[epoch 141] loss: 0.45007 accuracy: 0.8264 time: 44.2868s\n","[epoch 142] loss: 0.45341 accuracy: 0.8099 time: 44.5468s\n","[epoch 143] loss: 0.46841 accuracy: 0.8017 time: 45.2244s\n","[epoch 144] loss: 0.43206 accuracy: 0.8430 time: 45.5105s\n","[epoch 145] loss: 0.43593 accuracy: 0.8182 time: 45.8051s\n","[epoch 146] loss: 0.41052 accuracy: 0.8595 time: 46.0902s\n","[epoch 147] loss: 0.41761 accuracy: 0.8512 time: 46.3512s\n","[epoch 148] loss: 0.46261 accuracy: 0.8017 time: 46.6058s\n","[epoch 149] loss: 0.45916 accuracy: 0.7769 time: 46.8698s\n","[epoch 150] loss: 0.41376 accuracy: 0.8264 time: 47.1208s\n","[epoch 151] loss: 0.43187 accuracy: 0.8017 time: 47.3708s\n","[epoch 152] loss: 0.39466 accuracy: 0.8430 time: 47.6318s\n","[epoch 153] loss: 0.42838 accuracy: 0.8264 time: 47.9018s\n","[epoch 154] loss: 0.38494 accuracy: 0.8678 time: 48.1668s\n","[epoch 155] loss: 0.40775 accuracy: 0.8264 time: 48.4398s\n","[epoch 156] loss: 0.42578 accuracy: 0.8347 time: 48.7078s\n","[epoch 157] loss: 0.42036 accuracy: 0.7934 time: 48.9708s\n","[epoch 158] loss: 0.41580 accuracy: 0.7934 time: 49.2398s\n","[epoch 159] loss: 0.39281 accuracy: 0.8099 time: 49.6398s\n","[epoch 160] loss: 0.39103 accuracy: 0.8512 time: 49.9018s\n","[epoch 161] loss: 0.41498 accuracy: 0.7934 time: 50.1698s\n","[epoch 162] loss: 0.37631 accuracy: 0.8347 time: 50.4428s\n","[epoch 163] loss: 0.34620 accuracy: 0.8760 time: 50.7101s\n","[epoch 164] loss: 0.37974 accuracy: 0.8430 time: 50.9731s\n","[epoch 165] loss: 0.43760 accuracy: 0.8017 time: 51.2311s\n","[epoch 166] loss: 0.39064 accuracy: 0.8430 time: 51.5228s\n","[epoch 167] loss: 0.41194 accuracy: 0.7934 time: 51.7908s\n","[epoch 168] loss: 0.34104 accuracy: 0.8512 time: 52.0584s\n","[epoch 169] loss: 0.45756 accuracy: 0.7769 time: 52.3254s\n","[epoch 170] loss: 0.42212 accuracy: 0.7851 time: 52.5909s\n","[epoch 171] loss: 0.45972 accuracy: 0.7934 time: 52.9240s\n","[epoch 172] loss: 0.42422 accuracy: 0.8017 time: 53.2010s\n","[epoch 173] loss: 0.40310 accuracy: 0.8264 time: 53.4569s\n","[epoch 174] loss: 0.41650 accuracy: 0.7851 time: 53.7234s\n","[epoch 175] loss: 0.36871 accuracy: 0.8678 time: 53.9734s\n","[epoch 176] loss: 0.37588 accuracy: 0.8512 time: 54.2405s\n","[epoch 177] loss: 0.37558 accuracy: 0.8430 time: 54.5055s\n","[epoch 178] loss: 0.36661 accuracy: 0.8182 time: 54.7565s\n","[epoch 179] loss: 0.36386 accuracy: 0.8760 time: 55.0225s\n","[epoch 180] loss: 0.35428 accuracy: 0.8678 time: 55.3445s\n","[epoch 181] loss: 0.39096 accuracy: 0.8347 time: 55.6056s\n","[epoch 182] loss: 0.37172 accuracy: 0.8595 time: 55.8871s\n","[epoch 183] loss: 0.34619 accuracy: 0.8678 time: 56.1406s\n","[epoch 184] loss: 0.32748 accuracy: 0.9008 time: 56.4206s\n","[epoch 185] loss: 0.31699 accuracy: 0.8843 time: 56.7706s\n","[epoch 186] loss: 0.34628 accuracy: 0.8512 time: 57.0416s\n","[epoch 187] loss: 0.33617 accuracy: 0.8760 time: 57.4217s\n","[epoch 188] loss: 0.32137 accuracy: 0.9008 time: 57.7844s\n","[epoch 189] loss: 0.30316 accuracy: 0.9008 time: 58.0389s\n","[epoch 190] loss: 0.33085 accuracy: 0.8926 time: 58.2909s\n","[epoch 191] loss: 0.32644 accuracy: 0.8760 time: 58.5599s\n","[epoch 192] loss: 0.30390 accuracy: 0.9008 time: 58.8329s\n","[epoch 193] loss: 0.28481 accuracy: 0.9174 time: 59.1374s\n","[epoch 194] loss: 0.32669 accuracy: 0.8678 time: 59.4054s\n","[epoch 195] loss: 0.29571 accuracy: 0.8926 time: 59.6644s\n","[epoch 196] loss: 0.38624 accuracy: 0.8347 time: 61.5138s\n","[epoch 197] loss: 0.36986 accuracy: 0.8347 time: 61.7698s\n","[epoch 198] loss: 0.31943 accuracy: 0.8595 time: 62.6190s\n","[epoch 199] loss: 0.33717 accuracy: 0.8843 time: 62.8895s\n","[epoch 200] loss: 0.30809 accuracy: 0.9008 time: 63.1565s\n","[epoch 201] loss: 0.29789 accuracy: 0.8678 time: 63.4226s\n","[epoch 202] loss: 0.31077 accuracy: 0.8512 time: 63.6879s\n","[epoch 203] loss: 0.28348 accuracy: 0.8843 time: 63.9549s\n","[epoch 204] loss: 0.29670 accuracy: 0.9091 time: 64.2385s\n","[epoch 205] loss: 0.30829 accuracy: 0.8347 time: 64.5035s\n","[epoch 206] loss: 0.27769 accuracy: 0.9256 time: 64.7760s\n","[epoch 207] loss: 0.29027 accuracy: 0.8595 time: 65.0561s\n","[epoch 208] loss: 0.26899 accuracy: 0.8926 time: 65.3564s\n","[epoch 209] loss: 0.26490 accuracy: 0.8926 time: 65.6247s\n","[epoch 210] loss: 0.23450 accuracy: 0.8926 time: 65.9017s\n","[epoch 211] loss: 0.25924 accuracy: 0.9174 time: 66.1832s\n","[epoch 212] loss: 0.27853 accuracy: 0.9008 time: 66.4507s\n","[epoch 213] loss: 0.24416 accuracy: 0.9256 time: 66.7397s\n","[epoch 214] loss: 0.22623 accuracy: 0.9256 time: 67.0097s\n","[epoch 215] loss: 0.23791 accuracy: 0.9174 time: 67.2707s\n","[epoch 216] loss: 0.26312 accuracy: 0.8926 time: 67.5217s\n","[epoch 217] loss: 0.20428 accuracy: 0.9256 time: 67.7737s\n","[epoch 218] loss: 0.24102 accuracy: 0.9091 time: 68.0557s\n","[epoch 219] loss: 0.21821 accuracy: 0.9008 time: 68.3207s\n","[epoch 220] loss: 0.23758 accuracy: 0.9421 time: 68.5737s\n","[epoch 221] loss: 0.22851 accuracy: 0.9256 time: 68.8527s\n","[epoch 222] loss: 0.24762 accuracy: 0.9008 time: 69.1017s\n","[epoch 223] loss: 0.20097 accuracy: 0.9256 time: 69.3547s\n","[epoch 224] loss: 0.20717 accuracy: 0.9339 time: 69.6077s\n","[epoch 225] loss: 0.19673 accuracy: 0.9504 time: 69.8747s\n","[epoch 226] loss: 0.25972 accuracy: 0.8926 time: 70.2007s\n","[epoch 227] loss: 0.20745 accuracy: 0.9256 time: 70.6338s\n","[epoch 228] loss: 0.21299 accuracy: 0.9008 time: 70.8898s\n","[epoch 229] loss: 0.20965 accuracy: 0.9008 time: 71.1548s\n","[epoch 230] loss: 0.21256 accuracy: 0.9256 time: 71.4058s\n","[epoch 231] loss: 0.25876 accuracy: 0.8678 time: 71.6698s\n","[epoch 232] loss: 0.21106 accuracy: 0.9174 time: 71.9248s\n","[epoch 233] loss: 0.24509 accuracy: 0.8843 time: 72.1888s\n","[epoch 234] loss: 0.19343 accuracy: 0.9421 time: 72.4673s\n","[epoch 235] loss: 0.19989 accuracy: 0.9339 time: 72.7413s\n","[epoch 236] loss: 0.23310 accuracy: 0.9256 time: 73.0237s\n","[epoch 237] loss: 0.26907 accuracy: 0.8843 time: 73.3877s\n","[epoch 238] loss: 0.23656 accuracy: 0.8926 time: 73.6507s\n","[epoch 239] loss: 0.26517 accuracy: 0.8760 time: 73.9567s\n","[epoch 240] loss: 0.31649 accuracy: 0.8843 time: 74.3567s\n","[epoch 241] loss: 0.22202 accuracy: 0.9339 time: 74.6187s\n","[epoch 242] loss: 0.21829 accuracy: 0.8926 time: 74.8717s\n","[epoch 243] loss: 0.26579 accuracy: 0.9008 time: 75.1555s\n","[epoch 244] loss: 0.17246 accuracy: 0.9256 time: 75.4205s\n","[epoch 245] loss: 0.21206 accuracy: 0.9008 time: 75.7025s\n","[epoch 246] loss: 0.21181 accuracy: 0.9339 time: 75.9529s\n","[epoch 247] loss: 0.22386 accuracy: 0.9174 time: 76.2039s\n","[epoch 248] loss: 0.15583 accuracy: 0.9504 time: 76.6539s\n","[epoch 249] loss: 0.17407 accuracy: 0.9421 time: 76.9019s\n","[epoch 250] loss: 0.21311 accuracy: 0.9256 time: 77.1554s\n","[epoch 251] loss: 0.21376 accuracy: 0.9339 time: 77.4044s\n","[epoch 252] loss: 0.19872 accuracy: 0.9256 time: 77.6574s\n","[epoch 253] loss: 0.16594 accuracy: 0.9504 time: 77.9194s\n","[epoch 254] loss: 0.24678 accuracy: 0.8926 time: 78.1704s\n","[epoch 255] loss: 0.20008 accuracy: 0.9256 time: 78.4360s\n","[epoch 256] loss: 0.19932 accuracy: 0.9174 time: 78.7350s\n","[epoch 257] loss: 0.16225 accuracy: 0.9752 time: 79.0060s\n","[epoch 258] loss: 0.16518 accuracy: 0.9256 time: 79.2920s\n","[epoch 259] loss: 0.19898 accuracy: 0.9091 time: 79.7070s\n","[epoch 260] loss: 0.17057 accuracy: 0.9256 time: 80.1427s\n","[epoch 261] loss: 0.17159 accuracy: 0.9256 time: 80.5722s\n","[epoch 262] loss: 0.19658 accuracy: 0.9256 time: 80.8402s\n","[epoch 263] loss: 0.20727 accuracy: 0.9339 time: 81.1082s\n","[epoch 264] loss: 0.17123 accuracy: 0.9339 time: 81.3562s\n","[epoch 265] loss: 0.18297 accuracy: 0.9421 time: 81.6122s\n","[epoch 266] loss: 0.24172 accuracy: 0.8843 time: 81.8682s\n","[epoch 267] loss: 0.18663 accuracy: 0.9339 time: 82.1222s\n","[epoch 268] loss: 0.16706 accuracy: 0.9339 time: 82.3862s\n","[epoch 269] loss: 0.19452 accuracy: 0.9256 time: 82.6712s\n","[epoch 270] loss: 0.17244 accuracy: 0.9256 time: 82.9532s\n","[epoch 271] loss: 0.21623 accuracy: 0.8926 time: 83.2232s\n","[epoch 272] loss: 0.20687 accuracy: 0.9174 time: 83.5052s\n","[epoch 273] loss: 0.18593 accuracy: 0.9256 time: 83.9022s\n","[epoch 274] loss: 0.20402 accuracy: 0.9174 time: 84.2732s\n","[epoch 275] loss: 0.17688 accuracy: 0.9421 time: 84.5232s\n","[epoch 276] loss: 0.22046 accuracy: 0.9008 time: 84.7812s\n","[epoch 277] loss: 0.16479 accuracy: 0.9504 time: 85.0372s\n","[epoch 278] loss: 0.14421 accuracy: 0.9504 time: 85.3042s\n","[epoch 279] loss: 0.12060 accuracy: 0.9669 time: 85.5732s\n","[epoch 280] loss: 0.18802 accuracy: 0.9339 time: 85.8352s\n","[epoch 281] loss: 0.22970 accuracy: 0.9008 time: 86.2192s\n","[epoch 282] loss: 0.16575 accuracy: 0.9421 time: 86.4722s\n","[epoch 283] loss: 0.19855 accuracy: 0.9174 time: 86.7352s\n","[epoch 284] loss: 0.19319 accuracy: 0.9174 time: 86.9892s\n","[epoch 285] loss: 0.13836 accuracy: 0.9504 time: 87.2692s\n","[epoch 286] loss: 0.11744 accuracy: 0.9752 time: 87.5232s\n","[epoch 287] loss: 0.15400 accuracy: 0.9339 time: 87.8052s\n","[epoch 288] loss: 0.14924 accuracy: 0.9587 time: 88.0562s\n","[epoch 289] loss: 0.11829 accuracy: 0.9669 time: 88.3342s\n","[epoch 290] loss: 0.11040 accuracy: 0.9587 time: 88.7432s\n","[epoch 291] loss: 0.14184 accuracy: 0.9339 time: 89.2202s\n","[epoch 292] loss: 0.20306 accuracy: 0.9256 time: 89.4732s\n","[epoch 293] loss: 0.16509 accuracy: 0.9339 time: 89.7252s\n","[epoch 294] loss: 0.18825 accuracy: 0.9339 time: 90.0032s\n","[epoch 295] loss: 0.20468 accuracy: 0.9256 time: 90.2692s\n","[epoch 296] loss: 0.14759 accuracy: 0.9339 time: 90.5558s\n","[epoch 297] loss: 0.14000 accuracy: 0.9421 time: 90.8218s\n","[epoch 298] loss: 0.11033 accuracy: 0.9587 time: 91.1078s\n","[epoch 299] loss: 0.09762 accuracy: 0.9669 time: 91.4998s\n","[epoch 300] loss: 0.13521 accuracy: 0.9504 time: 91.7698s\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIX4r6-rivwN","executionInfo":{"status":"ok","timestamp":1670808182144,"user_tz":300,"elapsed":1709991,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"58e72c3a-a39f-43f1-827c-885c0597f3c4"}},{"cell_type":"code","execution_count":34,"source":["correct_test = 0\r\n","net.eval()\r\n","with torch.no_grad():\r\n","    for batch_idx, (data, label) in enumerate(test_loader):\r\n","        data, label = data.to(device), label.to(device)\r\n","        ##TODO: pass the data into the network and store the output\r\n","        outputs = net(data)\r\n","        ##TODO: Get the prediction from the output\r\n","        _, predicted = torch.max(outputs, 1)\r\n","        ##TODO: Calculate the correct number and add the number to correct_test\r\n","        correct_test += predicted.eq(label).sum()\r\n","\r\n","print('Accuracy on the test images: %.2f %%' % (100 * correct_test / len(test_set)))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 83.33 %\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fGgm-qMygjn","executionInfo":{"status":"ok","timestamp":1670808628949,"user_tz":300,"elapsed":446838,"user":{"displayName":"Kevin Brown","userId":"08982249951404104006"}},"outputId":"2d351eca-e225-4854-fc4d-122b9cd5fb72"}}]}